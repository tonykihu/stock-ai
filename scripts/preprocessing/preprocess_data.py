import os
import pandas as pd
from ta import add_all_ta_features

def load_us_data(file_path):
    """
    Load US stock CSV files generated by yfinance (multi-index format).
    yfinance outputs 3 header rows: Price, Ticker, Date.
    """
    df = pd.read_csv(file_path, header=[0, 1], skiprows=[2])

    # Flatten multi-index columns: keep just the first level (Price, Close, etc.)
    df.columns = [col[0] for col in df.columns]

    # First column is the date (unnamed or 'Price')
    df = df.rename(columns={df.columns[0]: "Date"})
    df["Date"] = pd.to_datetime(df["Date"])

    # Convert numeric columns
    for col in ["Close", "High", "Low", "Open", "Volume"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    return df

def load_kenya_data(file_path):
    """
    Load Kenya NSE CSV data.
    Columns: DATE, CODE, NAME, Day Price, Volume, etc.
    """
    df = pd.read_csv(file_path)

    # Standardize column names to match US format
    rename_map = {}
    if "DATE" in df.columns:
        rename_map["DATE"] = "Date"
    if "Day Price" in df.columns:
        rename_map["Day Price"] = "Close"
    if "Day High" in df.columns:
        rename_map["Day High"] = "High"
    if "Day Low" in df.columns:
        rename_map["Day Low"] = "Low"

    df = df.rename(columns=rename_map)

    if "Date" in df.columns:
        df["Date"] = pd.to_datetime(df["Date"], format="%d-%b-%y", errors="coerce")

    # Convert numeric columns
    for col in ["Close", "High", "Low"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    return df

def preprocess_data():
    """
    Loads US and Kenya stock data, adds technical indicators,
    and saves processed features to CSV.
    """
    os.makedirs("data/processed", exist_ok=True)

    # Load datasets
    us_data = load_us_data("data/us/aapl.csv")
    kenya_data = load_kenya_data("data/kenya/nse_latest.csv")

    # Tag markets
    us_data["Market"] = "US"
    kenya_data["Market"] = "Kenya"
    combined = pd.concat([us_data, kenya_data], ignore_index=True)

    # Save combined raw data
    combined.to_csv("data/processed/combined.csv", index=False)

    # Add technical indicators only for US data (has full OHLCV)
    us_only = combined[combined["Market"] == "US"].copy()

    required_cols = ["Open", "High", "Low", "Close", "Volume"]
    if all(col in us_only.columns for col in required_cols):
        us_only = us_only.dropna(subset=required_cols)
        us_only = add_all_ta_features(
            us_only, open="Open", high="High", low="Low",
            close="Close", volume="Volume"
        )

    # Map ta library column names to our standard names
    column_mapping = {
        "momentum_rsi": "rsi_14",
        "trend_macd": "macd",
        "trend_sma_fast": "sma_50",
        "volume_obv": "volume_obv"
    }

    for ta_name, our_name in column_mapping.items():
        if ta_name in us_only.columns:
            us_only = us_only.rename(columns={ta_name: our_name})

    # Keep key features
    features = ["rsi_14", "macd", "sma_50", "volume_obv"]
    available_features = [f for f in features if f in us_only.columns]
    keep_cols = available_features + ["Close", "Market", "Date"]
    us_only[keep_cols].to_csv("data/processed/features.csv", index=False)
    print(f"Features saved with columns: {keep_cols}")
    print(f"Rows: {len(us_only)}")

if __name__ == "__main__":
    preprocess_data()
